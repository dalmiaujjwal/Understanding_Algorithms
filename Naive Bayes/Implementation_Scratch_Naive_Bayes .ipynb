{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier - Implementation from scratch \n",
    "The notbook contains the code to implement the Naive Bayes Classifier from Scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.special import logsumexp\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "- This is a kaggle dataset which has news text articles along with the category they belong to like business, sports etc.\n",
    "- The objective is to make a classifier which can predict the category of news article given it's text\n",
    "- The sample records of the dataset are shown for your reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_dataset = pd.read_csv(\"C:\\\\Ujjwal\\\\Analytics\\\\Datasets\\\\News Classification\\\\News_train.csv\")\n",
    "inp_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the articles to remove the unwanted characters\n",
    "- In this step we are cleaning the dataset and dividing it in to test and train set\n",
    "- The data cleaning is done in the function defined as **text_clean**. Given the focus is on identifying popular words which come in specific category of articles, the function removes all the numbers, puncutations and special characters from the text. Moreover, any extra spaces are replaced with single space.\n",
    "- Finally, we are splitting the data in to train and test set using *sklearn's function* **test_train_split**\n",
    "- Notice the number of records in original, training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text_series):\n",
    "    text_series = text_series.str.lower()\n",
    "    clean_1 = text_series.str.replace(r\"[^a-zA-Z\\s]\",\"\")\n",
    "    clean_2 = clean_1.str.replace(r\"\\s+\", \" \")\n",
    "    return clean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_dataset[\"Text_Clean\"] = text_clean(inp_dataset[\"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bag of Words\n",
    "- In this step we are creating a dataframe which has the count frequency of each word in each document\n",
    "- This is done using *sklearn's* **CountVectorizer** function. We have **passed the argument stop_words as \"english\" so that the function can remove the english stop words on it's own**.\n",
    "- Observe the sample records from the dataframe. The number 1 below abacus in record 4 indicates that the **word Abacus came once in this document**. \n",
    "\n",
    "**Note:**\n",
    "\n",
    "- Since the number of unique words across all the documents are very high, all the words are not visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aac</th>\n",
       "      <th>aadc</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaltra</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aashare</th>\n",
       "      <th>...</th>\n",
       "      <th>zonealarm</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutons</th>\n",
       "      <th>zvonareva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 25062 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaas  aac  aadc  aaliyah  aaltra  aamir  aaron  aashare  ...  \\\n",
       "4   0    0     0    0     0        0       0      0      0        0  ...   \n",
       "5   0    0     0    0     0        0       0      0      0        0  ...   \n",
       "6   0    0     0    0     0        0       0      0      0        0  ...   \n",
       "7   0    0     0    0     0        0       0      0      0        0  ...   \n",
       "\n",
       "   zonealarm  zones  zoom  zooms  zooropa  zorro  zuluaga  zurich  zutons  \\\n",
       "4          0      0     0      0        0      0        0       0       0   \n",
       "5          0      0     0      0        0      0        0       0       0   \n",
       "6          0      0     0      0        0      0        0       0       0   \n",
       "7          0      0     0      0        0      0        0       0       0   \n",
       "\n",
       "   zvonareva  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "\n",
       "[4 rows x 25062 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cnt_Vec = CountVectorizer(stop_words=\"english\")\n",
    "BOW = Cnt_Vec.fit_transform(inp_dataset[\"Text_Clean\"]).toarray()\n",
    "BOW_Df = pd.DataFrame(BOW, columns=Cnt_Vec.get_feature_names())\n",
    "BOW_Df[4:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Dataframes & Creating training and test set\n",
    "- To get the article category values along with the word frequency, we are merging the 2 datasets\n",
    "- This is done because we will be implementing the Naive Bayes approach from scratch and not using sklearn's inbuilt functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aac</th>\n",
       "      <th>aadc</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>...</th>\n",
       "      <th>zonealarm</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutons</th>\n",
       "      <th>zvonareva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>worldcom exboss launches defence lawyers defen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25066 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category  \\\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business   \n",
       "1        154  german business confidence slides german busin...  business   \n",
       "\n",
       "                                          Text_Clean  aa  aaa  aaas  aac  \\\n",
       "0  worldcom exboss launches defence lawyers defen...   0    0     0    0   \n",
       "1  german business confidence slides german busin...   0    0     0    0   \n",
       "\n",
       "   aadc  aaliyah  ...  zonealarm  zones  zoom  zooms  zooropa  zorro  zuluaga  \\\n",
       "0     0        0  ...          0      0     0      0        0      0        0   \n",
       "1     0        0  ...          0      0     0      0        0      0        0   \n",
       "\n",
       "   zurich  zutons  zvonareva  \n",
       "0       0       0          0  \n",
       "1       0       0          0  \n",
       "\n",
       "[2 rows x 25066 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_dataset_final = pd.merge(inp_dataset, BOW_Df, left_index=True, right_index=True, how = \"left\")\n",
    "inp_dataset_final.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidating Bag of Words on the basis of News Categories\n",
    "- In this section we are grouping all the word frequencies on the basis of different news categories they fall in\n",
    "- An additional column is added to the dataframe which contains the count of all the words across the documents in specific category\n",
    "- The ArticleId column is having the count of articles in each category\n",
    "- Refer to the sample records as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aac</th>\n",
       "      <th>aadc</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaltra</th>\n",
       "      <th>aamir</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutons</th>\n",
       "      <th>zvonareva</th>\n",
       "      <th>sum_all_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>56255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25065 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category  ArticleId  aa  aaa  aaas  aac  aadc  aaliyah  aaltra  aamir  \\\n",
       "0       business        336   0    0     0    0     0        0       0      0   \n",
       "1  entertainment        273   0    0     0    0     0        4       1      1   \n",
       "2       politics        274   1    0     0    0     0        0       0      0   \n",
       "3          sport        346   0    4     1    3     0        0       0      0   \n",
       "4           tech        261   0    0     1    0     3        0       0      0   \n",
       "\n",
       "   ...  zones  zoom  zooms  zooropa  zorro  zuluaga  zurich  zutons  \\\n",
       "0  ...      3     0      0        0      0        0       2       0   \n",
       "1  ...      0     0      0        1      2        0       0       1   \n",
       "2  ...      0     0      0        0      0        0       0       0   \n",
       "3  ...      0     0      0        0      0        1       5       0   \n",
       "4  ...      1     3      2        0      0        0       0       0   \n",
       "\n",
       "   zvonareva  sum_all_words  \n",
       "0          0          58683  \n",
       "1          0          46998  \n",
       "2          0          61750  \n",
       "3          4          56255  \n",
       "4          0          65823  \n",
       "\n",
       "[5 rows x 25065 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_dataset = inp_dataset_final.groupby(\"Category\").agg({col:\"count\" if col == \"ArticleId\" else \"sum\" for col in inp_dataset_final.columns})\n",
    "cols = [col for col in cons_dataset.columns if col not in [\"Text\", \"Category\", \"Text_Clean\"]]\n",
    "cons_dataset_updated = cons_dataset[cols].copy()\n",
    "cons_dataset_updated.reset_index(inplace=True)\n",
    "cons_dataset_updated[\"sum_all_words\"] = cons_dataset_updated.iloc[:,2:].apply(lambda x: np.sum(x), axis=1)\n",
    "cons_dataset_updated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Probability Table\n",
    "- Using the consolidated table we created in the previous section, we will now calculate the probabilities of each word occuring in each artcile category\n",
    "- Laplace smoothing is also built in to ensure that words with 0 frequency are taken care of. This table will be used to calculate the probability of all the test documents\n",
    "- See the sample dataframe output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "prob_table = pd.DataFrame()\n",
    "prob_table[\"Category\"] = cons_dataset_updated[\"Category\"]\n",
    "prob_table[\"p_C\"] = cons_dataset_updated[\"ArticleId\"]/inp_dataset_final.shape[0]\n",
    "cols = [col for col in cons_dataset_updated.columns if col not in [\"Category\", \"ArticleId\", \"sum_all_words\"]]\n",
    "no_of_cols = len(cols)\n",
    "for col in cols:\n",
    "    prob_table[col] = (cons_dataset_updated[col]+alpha)/(cons_dataset_updated[\"sum_all_words\"] + (alpha*no_of_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>p_C</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aac</th>\n",
       "      <th>aadc</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaltra</th>\n",
       "      <th>aamir</th>\n",
       "      <th>...</th>\n",
       "      <th>zonealarm</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutons</th>\n",
       "      <th>zvonareva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>0.225503</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.183221</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>0.183893</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>0.232215</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category       p_C        aa       aaa      aaas       aac      aadc  \\\n",
       "0       business  0.225503  0.000012  0.000012  0.000012  0.000012  0.000012   \n",
       "1  entertainment  0.183221  0.000014  0.000014  0.000014  0.000014  0.000014   \n",
       "2       politics  0.183893  0.000023  0.000012  0.000012  0.000012  0.000012   \n",
       "3          sport  0.232215  0.000012  0.000061  0.000025  0.000049  0.000012   \n",
       "4           tech  0.175168  0.000011  0.000011  0.000022  0.000011  0.000044   \n",
       "\n",
       "    aaliyah    aaltra     aamir  ...  zonealarm     zones      zoom     zooms  \\\n",
       "0  0.000012  0.000012  0.000012  ...   0.000012  0.000048  0.000012  0.000012   \n",
       "1  0.000069  0.000028  0.000028  ...   0.000014  0.000014  0.000014  0.000014   \n",
       "2  0.000012  0.000012  0.000012  ...   0.000012  0.000012  0.000012  0.000012   \n",
       "3  0.000012  0.000012  0.000012  ...   0.000012  0.000012  0.000012  0.000012   \n",
       "4  0.000011  0.000011  0.000011  ...   0.000022  0.000022  0.000044  0.000033   \n",
       "\n",
       "    zooropa     zorro   zuluaga    zurich    zutons  zvonareva  \n",
       "0  0.000012  0.000012  0.000012  0.000036  0.000012   0.000012  \n",
       "1  0.000028  0.000042  0.000014  0.000014  0.000028   0.000014  \n",
       "2  0.000012  0.000012  0.000012  0.000012  0.000012   0.000012  \n",
       "3  0.000012  0.000012  0.000025  0.000074  0.000012   0.000061  \n",
       "4  0.000011  0.000011  0.000011  0.000011  0.000011   0.000011  \n",
       "\n",
       "[5 rows x 25064 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a word tokenizer\n",
    "- Here we are defining a word tokenizer function to split the test articles in to individual words\n",
    "- We could have used our count vectorizer variable to transform the text but just to demonstrate the process of tokenizing, this funciton is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\",\" \", text)\n",
    "    list_of_words = text.split(\" \")\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the classification\n",
    "- Using the probability table creating in the previous section, the test dataset articles will be classified\n",
    "- As can be seen fromt he results, close to 95% of the documents got correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"game went really good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pd.DataFrame()\n",
    "prob[\"Category\"] = prob_table[\"Category\"]\n",
    "prob[\"prob\"] = prob_table['p_C']\n",
    "for val in wt(text):\n",
    "    if val in prob_table.columns:\n",
    "        prob[\"prob\"] = prob[\"prob\"] * prob_table[val]\n",
    "    else:\n",
    "        prob[\"prob\"] = prob[\"prob\"] * 1\n",
    "prob[\"probability\"] = prob[\"prob\"]/prob[\"prob\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>prob</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>1.823821e-16</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>2.270805e-14</td>\n",
       "      <td>0.012974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>7.476354e-15</td>\n",
       "      <td>0.004271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>1.664447e-12</td>\n",
       "      <td>0.950936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>5.551025e-14</td>\n",
       "      <td>0.031714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category          prob  probability\n",
       "0       business  1.823821e-16     0.000104\n",
       "1  entertainment  2.270805e-14     0.012974\n",
       "2       politics  7.476354e-15     0.004271\n",
       "3          sport  1.664447e-12     0.950936\n",
       "4           tech  5.551025e-14     0.031714"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating probability table of training dataset using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Multi_NB = MultinomialNB(alpha=1)\n",
    "cols = [col for col in inp_dataset_final.columns if col not in [\"Category\",\"ArticleId\", \"Text\", \"Text_Clean\"]]\n",
    "Multi_NB.fit(inp_dataset_final[cols], inp_dataset_final[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = wt(text)\n",
    "text_dict = {}\n",
    "for word in text_list:\n",
    "    if word in text_dict:\n",
    "        text_dict[word] +=1\n",
    "    else:\n",
    "        text_dict[word] = 1\n",
    "for word in cols:\n",
    "    if word not in text_dict:\n",
    "        text_dict[word] = 0\n",
    "    else:\n",
    "        pass\n",
    "df = pd.DataFrame(text_dict, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aa          -11.335532\n",
       "aaa         -11.335532\n",
       "aaas        -11.335532\n",
       "aac         -11.335532\n",
       "aadc        -11.335532\n",
       "               ...    \n",
       "zorro       -11.335532\n",
       "zuluaga     -11.335532\n",
       "zurich      -10.236919\n",
       "zutons      -11.335532\n",
       "zvonareva   -11.335532\n",
       "Name: 0, Length: 25062, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(prob_table.iloc[0,2:].astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.33553175, -11.33553175, -11.33553175, ..., -10.23691946,\n",
       "        -11.33553175, -11.33553175],\n",
       "       [-11.18525438, -11.18525438, -11.18525438, ..., -11.18525438,\n",
       "        -10.4921072 , -11.18525438],\n",
       "       [-10.67835296, -11.37150014, -11.37150014, ..., -11.37150014,\n",
       "        -11.37150014, -11.37150014],\n",
       "       [-11.30611038,  -9.69667246, -10.6129632 , ...,  -9.51435091,\n",
       "        -11.30611038,  -9.69667246],\n",
       "       [-11.41735025, -11.41735025, -10.72420307, ..., -11.41735025,\n",
       "        -11.41735025, -11.41735025]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Multi_NB.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01947449, 0.02886343, 0.02750577, 0.90234589, 0.02181042]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(arr - logsumexp(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arr = np.dot(df, Multi_NB.feature_log_prob_.T) + Multi_NB.class_log_prior_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
